{"cells":[{"cell_type":"code","execution_count":null,"id":"6f47140c","metadata":{"id":"6f47140c","outputId":"7f8fe2e0-4613-47aa-9056-8c01c48f9517"},"outputs":[],"source":["# Required imports\n","import os\n","import pandas as pd\n","import json"]},{"cell_type":"markdown","id":"2-8zyaOWIZEK","metadata":{"id":"2-8zyaOWIZEK"},"source":["# First we extract the 'country_code', 'city_name', 'location_name' from the 'location' column and store these in new columns"]},{"cell_type":"code","execution_count":null,"id":"6a6e66c2","metadata":{"id":"6a6e66c2","outputId":"1a50afe1-2029-4fb5-e731-1c56e32cb230"},"outputs":[],"source":["# Load the csv_file into a pandas dataframe\n","csv_file = 'csv_metadata.csv'\n","df = pd.read_csv(csv_file)"]},{"cell_type":"code","execution_count":null,"id":"cb23d71c","metadata":{"id":"cb23d71c"},"outputs":[],"source":["# Function to extract the required fields\n","def extract_fields(location_entry):\n","    try:\n","        if isinstance(location_entry, str):  # Check if the entry is a string\n","            try:\n","                # Fix the internal JSON string first by converting the whole string into a Python dictionary\n","                location_dict = eval(location_entry)\n","\n","               # Check if 'address_json' is not None before parsing\n","                if location_dict.get('address_json') is not None:\n","                    # Parse the JSON string in the 'address_json' field\n","                    address_info = json.loads(location_dict.get('address_json', '{}'))\n","                else:\n","                    address_info = {}  # Assign an empty dictionary if 'address_json' is None\n","\n","                country_code = address_info.get('country_code', None)\n","                city_name = address_info.get('city_name', None)\n","                name = location_dict.get('name', None)\n","\n","                return pd.Series([country_code, city_name, name])\n","            except (json.JSONDecodeError, SyntaxError) as e:\n","                print(f\"Error decoding JSON: {location_entry}\")\n","                print(f\"Type: {type(location_entry)}\")\n","                print(f\"Exception: {e}\")\n","                return pd.Series([None, None, None])\n","        else:\n","            # Return None for NaN or other unexpected types\n","            return pd.Series([None, None, None])\n","    except(TypeError) as e:\n","        print(f\"Error decoding JSON: {location_entry}\")\n","        print(f\"Type: {type(location_entry)}\")\n","        print(f\"Exception: {e}\")\n","        return pd.Series([None, None, None])"]},{"cell_type":"code","execution_count":null,"id":"9abcb3a6","metadata":{"id":"9abcb3a6"},"outputs":[],"source":["# Extract the location information\n","df[['country_code', 'city_name', 'location_name']] = df['location'].progress_apply(extract_fields)"]},{"cell_type":"markdown","id":"5kRC-wwSI-PD","metadata":{"id":"5kRC-wwSI-PD"},"source":["# Now we rename the column names for simplicity and drop unecessary columns"]},{"cell_type":"code","execution_count":null,"id":"cvpM1EO6JEBH","metadata":{"id":"cvpM1EO6JEBH"},"outputs":[],"source":["# Defining a column name map for the renaming\n","column_mapping = {\n","    'owner.username': 'username',\n","    'owner.full_name': 'full_name',\n","    'owner.is_verified': 'is_verified',\n","    'owner.id': 'owner_id',\n","    'owner.is_private': 'is_private',\n","    'edge_media_preview_like.count': 'like_count',\n","    'count(edge_media_to_tagged_user.edges)': 'tagged_user_count',\n","    'id': 'post_id',\n","    'edge_media_to_parent_comment.count': 'comment_count',\n","    'taken_at_timestamp': 'timestamp',\n","    '__typename': 'post_type',\n","}"]},{"cell_type":"code","execution_count":null,"id":"yGPFVD8HJMaG","metadata":{"id":"yGPFVD8HJMaG"},"outputs":[],"source":["# Renaming the columns according to the mapping\n","df.rename(columns=column_mapping, inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"kqCSAnF0JRd4","metadata":{"id":"kqCSAnF0JRd4"},"outputs":[],"source":["# Drop the 'location' column, as we have already extracted the relevant location data\n","modified_csv.drop(columns=['location', ], inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"a94e020c","metadata":{"id":"a94e020c"},"outputs":[],"source":["# Simply storing the final dataframe in the respective csv file\n","df.to_csv(\"metadata_with_extracted_location.csv\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":5}
