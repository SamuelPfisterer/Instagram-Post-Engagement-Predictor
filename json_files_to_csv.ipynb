{"cells":[{"cell_type":"code","execution_count":null,"id":"3fe095bd-dbd2-414d-a49a-ff7f6c898a27","metadata":{"id":"3fe095bd-dbd2-414d-a49a-ff7f6c898a27","outputId":"f1927631-ed49-4d82-fd7e-db3b502282dd"},"outputs":[],"source":["# Necessary imports\n","import os\n","import pandas as pd\n","import json\n"]},{"cell_type":"markdown","id":"9qOuOZSiJiYH","metadata":{"id":"9qOuOZSiJiYH"},"source":["# Description\n","We transform the json files (each json file stores the metadata of one instagram post) into one single csv file, that stores the metadata for all the posts. Each row in the final csv file corresponds to one post and each column corresponds to specific metadata.\n","\n","First we define two functions and apply them then to json files.\n","1. Function ('extract_data'): Transforms each json file into a dictionary\n","2. Function ('convert_info_files_to_csv'): Iterates over all json files, applies 'extract_data to each file and combines the resulting dictionaries in a resulting csv file"]},{"cell_type":"markdown","id":"tSPa-g2wLie_","metadata":{"id":"tSPa-g2wLie_"},"source":["# Function definitions"]},{"cell_type":"code","execution_count":null,"id":"1851a52f-f9ec-464d-8ca1-7265b63a8ff0","metadata":{"id":"1851a52f-f9ec-464d-8ca1-7265b63a8ff0"},"outputs":[],"source":["# Function that extracts all the necessary data from a given json file\n","# Input: 'json_data' – the json object corresponding to the specific json file\n","# Input: 'file_name' – the file_path (string) to the corresponding json_file\n","# Output: data – a dictionary containg all the relevant data of the input json file\n","\n","def extract_data(json_data, file_name):\n","    # Extract required fields from JSON data\n","    owner = json_data['owner']\n","    edge_media_preview_like = json_data['edge_media_preview_like']\n","    edge_media_to_tagged_user = json_data['edge_media_to_tagged_user']\n","\n","    # Handle different key names for comments\n","    try:\n","        edge_media_to_parent_comment = json_data['edge_media_to_comment']\n","    except KeyError:\n","        edge_media_to_parent_comment = json_data['edge_media_to_parent_comment']\n","\n","    edge_media_to_caption = json_data['edge_media_to_caption']\n","\n","    # Handle cases where optional fields might be missing\n","    location = json_data.get('location', None)\n","    is_ad = json_data.get('is_ad', None)\n","    comments_disabled = json_data.get('comments_disabled', None)\n","    is_video = json_data.get('is_video', None)\n","    __typename = json_data.get('__typename', None)\n","\n","    # Extract the text of the first element in the array of edge_media_to_caption.edges\n","    caption_text = None\n","    if edge_media_to_caption and edge_media_to_caption['edges']:\n","        caption_text = edge_media_to_caption['edges'][0]['node']['text']\n","\n","    country_code = None\n","    if location and location['address_json']:\n","        location_cc = json.load(location['address_json'])\n","        country_code = location_cc[\"country_code\"]\n","\n","    # Create a dictionary with the extracted fields\n","    data = {\n","        'file_name': file_name,\n","        'owner.username': owner['username'],\n","        'owner.full_name': owner['full_name'],\n","        'owner.is_verified': owner['is_verified'],\n","        'owner.id': owner['id'],\n","        'owner.is_private': owner['is_private'],\n","        'edge_media_preview_like.count': edge_media_preview_like['count'],\n","        'count(edge_media_to_tagged_user.edges)': len(edge_media_to_tagged_user['edges']),\n","        'location': location,\n","        'is_ad': is_ad,\n","        'id': json_data['id'],\n","        'edge_media_to_parent_comment.count': edge_media_to_parent_comment['count'],\n","        'taken_at_timestamp': json_data['taken_at_timestamp'],\n","        'comments_disabled': comments_disabled,\n","        'is_video': is_video,\n","        '__typename': __typename,\n","        'caption_text': caption_text,\n","        'country_code': country_code\n","    }\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"id":"99c1d7eb-f45c-44c2-a787-e283c00453f1","metadata":{"id":"99c1d7eb-f45c-44c2-a787-e283c00453f1"},"outputs":[],"source":["# Function that converts all the json files into a singel csv file\n","# Input: Takes input_dir (the directory path where all the json files are stored), the output_file (name of the output csv file)\n","# and a start/ end index, that indicates which json files it should connvert as input parameters\n","# Result: Writes the csv file (output_file)\n","\n","def convert_info_files_to_csv(input_dir, output_file, start_index=0, end_index=100):\n","    # List all .info files in the directory\n","    info_files = [f for f in os.listdir(input_dir) if f.endswith('.info')]\n","\n","    # Slice the list to include only the first `max_files` files\n","    info_files = info_files[start_index:end_index]\n","\n","    # Initialize a list to store all data\n","    all_data = []\n","\n","    count = 0\n","\n","    # Loop through each file and extract data\n","    for index, file in enumerate(info_files):\n","        file_path = os.path.join(input_dir, file)\n","\n","        # Read the JSON file\n","        try:\n","            # Read the JSON file\n","            with open(file_path, 'r') as f:\n","                json_data = json.load(f)\n","        except json.JSONDecodeError:\n","            print(f\"JSONDecodeError at index {index + start_index} for file {file}\")\n","            continue\n","\n","        # Extract data and append to the list\n","        data = extract_data(json_data, file)\n","        all_data.append(data)\n","\n","    # Convert the list of data into a pandas DataFrame\n","    df = pd.DataFrame(all_data)\n","\n","    # Write the DataFrame to a CSV file\n","    df.to_csv(output_file, index=False)"]},{"cell_type":"markdown","id":"uKblFx3YLncu","metadata":{"id":"uKblFx3YLncu"},"source":["# Applying the Functions"]},{"cell_type":"code","execution_count":null,"id":"8431a467-0040-4298-a21e-2682a3186587","metadata":{"id":"8431a467-0040-4298-a21e-2682a3186587"},"outputs":[],"source":["# Define the directory, where all the json files are stored\n","input_dir = '/Users/samuelpfisterer/Downloads/7zipmac/extracted_files/info'"]},{"cell_type":"code","execution_count":null,"id":"fac357de-cb76-48bf-ba09-b8f83a851188","metadata":{"id":"fac357de-cb76-48bf-ba09-b8f83a851188"},"outputs":[],"source":["# Define the name of the csv file, where all the combined metadata from all the instagram post json files will be stored\n","output_file = 'csv_metadata.csv'"]},{"cell_type":"code","execution_count":null,"id":"ee12a113-8a5d-4b05-ade2-92c6ea6c8db1","metadata":{"collapsed":true,"id":"ee12a113-8a5d-4b05-ade2-92c6ea6c8db1","outputId":"0a4528e9-202d-4804-b81d-87f83dd1bbb9"},"outputs":[],"source":["# Call the function, that converts creates the csv file with all the metadata.\n","# start_index = 0 and end_index = 600000 as we want to metadata for the first 6000000 json files, i.e. instagram posts\n","convert_info_files_to_csv(input_dir, output_file, start_index = 0 , end_index = 600000)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1XqEXmGWHK0XRk9teBQ0iXhNDdsZbrSU2","timestamp":1724065150435}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":5}
